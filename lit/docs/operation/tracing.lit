\title{Tracing}{tracing}

\use-plugin{concourse-docs}

\warn{This is an \bold{experimental} feature.}

Tracing in Concourse enables the delivery of traces related to the internal
processes that go into running builds, and other internal operations, breaking
them down by time, and component.

It leverages the (\link{OpenTelemetry}{https://opentelemetry.io/}) SDK to allow support for many
platforms. Currently tracing can be configured to integrates with:

\list{
  \link{Jaeger}{https://www.jaegertracing.io/}
}{
  \link{Google Cloud Trace}{https://cloud.google.com/trace} (Stackdriver)
}{
  \link{Honeycomb.io}{https://honeycomb.io}
}{
  \link{OpenTelemetry Protocol Exporter}{https://github.com/open-telemetry/opentelemetry-go/tree/master/exporters/otlp}
}

\section{
  \title{Configuring Tracing}

  To export spans to Jaeger, specify the Thrift HTTP endpoint of the Jaeger
  collector:

  \codeblock{bash}{{{
  CONCOURSE_TRACING_JAEGER_ENDPOINT=http://jaeger:14268/api/traces
  }}}

  To export spans to Google Cloud Trace, specify the GCP Project ID:

  \codeblock{bash}{{{
  CONCOURSE_TRACING_STACKDRIVER_PROJECTID=your-gcp-project-id
  }}}

  Note that suitable GCP credentials must be available, via the usual
  \link{\code{GOOGLE_APPLICATION_CREDENTIALS} environment variable}{https://cloud.google.com/docs/authentication/getting-started#setting_the_environment_variable},
  the default location that the \code{gcloud} CLI expects, or from GCP's
  metadata server (if Concourse is deployed on GCP).

  To export spans the \link{OpenTelemetry Collector}{https://github.com/open-telemetry/opentelemetry-collector} via the OTLP Exporter, specify your collector access endpoint:

  \codeblock{bash}{{{
  CONCOURSE_TRACING_OTLP_ADDRESS=otel-collector.example.com:4317
  CONCOURSE_TRACING_OTLP_USE_TLS=false
  }}}

  To export spans to \link{Lightstep}{https://opentelemetry.lightstep.com/} via the OTLP Exporter, specify your collector access token and endpoint:

  \codeblock{bash}{{{
  CONCOURSE_TRACING_OTLP_ADDRESS=ingest.lightstep.com:443
  CONCOURSE_TRACING_OTLP_HEADERS=lightstep-access-token:mysupersecrettoken
  }}}


  To export spans to \link{Elastic Observability}{https://www.elastic.co/guide/en/apm/get-started/current/open-telemetry-elastic.html} via the OTLP Exporter, specify your Elastic APM secret token and endpoint:

  \codeblock{bash}{{{
  CONCOURSE_TRACING_OTLP_ADDRESS=elastic-apm-server.example.com:443
  CONCOURSE_TRACING_OTLP_HEADERS=Authorization=Bearer your-secret-token
  }}}


  To export spans to Honeycomb.io, specify the API key, dataset and
  optionally the service name:

  \codeblock{bash}{{{
  CONCOURSE_TRACING_HONEYCOMB_API_KEY=your-honeycomb-api-key
  CONCOURSE_TRACING_HONEYCOMB_DATASET=your-honeycomb-dataset
  CONCOURSE_TRACING_HONEYCOMB_SERVICE_NAME=service-name-for-concourse  # NOTE: Optional. Defaults to "concourse"
  }}}
}

\section{
  \title{Trace context propagation}
  When tracing is enabled, trace context propagation is activated in pipeline tasks thanks to the 
  injection of the environment variable \code{TRACEPARENT} in \code{run} commands.
  The environment variable \code{TRACEPARENT} complies with the 
  \link{W3C Trace Context}{https://www.w3.org/TR/trace-context/} specification.
}

\section{
  \title{What's emitted?}

  Below is a summary of the various operations that Concourse currently traces.
  They are arranged like a call tree, so that for each operation described, its
  sub-operations are described indented immediately below.

  \list{
    \code{scanner.Run} -- An execution of the \reference{checker}, responsible
    for determining which resources need to be checked.
    \list{
      \code{scanner.check} -- This operation simply represents inserting the
      check in the database.
    }
  }{
    \code{scheduler.Run} -- This represents one tick of the \reference{scheduler}.
    \list{
      \code{schedule-job} -- this is the same operation scoped to a single job.
        \list{
        \code{Algorithm.Compute} -- this is where the \reference{algorithm}
        determines inputs for a job. Each of the resolvers below describes a
        different strategy for determining inputs, depending on the job's config.
        \list{
          \code{individualResolver.Resolve} -- This is used to determine versions
          input to a \reference{get-step} without
          \reference{schema.get.passed}{\code{passed}} constraints.
        }{
          \code{groupResolver.Resolve} -- This is the juicy part of the algorithm,
          which deals with
          \reference{schema.get.passed}{\code{passed}} constraints.
        }{
          \code{pinnedResolver.Resolve} -- This operation is used to determine
          inputs when \reference{version-pinning} is at play.
        }
      }{
        \code{job.EnsurePendingBuildExists} -- This is where a new build, if
        deemed necessary by scheduling constraints, will be inserted into the
        database. This operation follows from \code{checker.Run} above and will
        appear under the same trace as the check which produced the resource
        version responsible for triggering the new build.
      }
    }
  }{
    \code{build} -- this is the primary operation performed by the
    \reference{build-tracker}. When a build is automatically triggered, this
    span follows from the \code{job.EnsurePendingBuildExists} operation which
    created the build, appearing in the same trace.
    \list{
      \code{get} -- this tracks the execution of a \reference{get-step}.
    }{
      \code{put} -- this tracks the execution of a \reference{put-step}.
    }{
      \code{task} -- this tracks the execution of a \reference{task-step}.
    }{
      \code{set_pipeline} -- this tracks the execution of a \reference{set-pipeline-step}.
    }{
      \code{load_var} -- this tracks the execution of a \reference{load-var-step}.
    }
  }
}
